{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26213,"status":"ok","timestamp":1675354772418,"user":{"displayName":"‰∏≠Áî∞ÂÖâÈöÜ","userId":"06690068059315868411"},"user_tz":-540},"id":"26dWwJaks2rT","outputId":"13d8fc97-e302-403e-d8a5-ccf963686897"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1675354772420,"user":{"displayName":"‰∏≠Áî∞ÂÖâÈöÜ","userId":"06690068059315868411"},"user_tz":-540},"id":"s60gXvk6s2rW","outputId":"f0498890-af7b-474c-f41c-ffbfc515b5e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/catalyst_metric_learning_defect\n"]}],"source":["import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/catalyst_metric_learning_defect')\n","\n","!pwd"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26668,"status":"ok","timestamp":1675354799078,"user":{"displayName":"‰∏≠Áî∞ÂÖâÈöÜ","userId":"06690068059315868411"},"user_tz":-540},"id":"NgqvaDfks2rX","outputId":"6b6fbb1b-7417-4b6c-ac68-84a9affdbbd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: accelerate 0.16.0\n","Uninstalling accelerate-0.16.0:\n","  Successfully uninstalled accelerate-0.16.0\n"]}],"source":["!pip install -q timm wandb catalyst &> /dev/null\n","!pip install -q hydra-core --upgrade &> /dev/null\n","!pip uninstall accelerate -y\n","!pip install accelerate==0.15.0 &> /dev/null"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675354799079,"user":{"displayName":"‰∏≠Áî∞ÂÖâÈöÜ","userId":"06690068059315868411"},"user_tz":-540},"id":"eALvD3qis2rY","outputId":"5b11bb9d-381e-4984-84f8-8017c963ed83"},"outputs":[{"output_type":"stream","name":"stdout","text":["'1. train.ipynb'\t config   log\t  notebooks   sanity_test.py   submit\n","'2. sanity_test.ipynb'\t input\t  model   output      src\t       train.py\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3b7TU8Y7Ei7","executionInfo":{"status":"ok","timestamp":1675354830180,"user_tz":-540,"elapsed":31108,"user":{"displayName":"‰∏≠Áî∞ÂÖâÈöÜ","userId":"06690068059315868411"}},"outputId":"521cceaa-7b8c-456d-dbba-25c6166ddf6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70656,"status":"ok","timestamp":1675356619533,"user":{"displayName":"‰∏≠Áî∞ÂÖâÈöÜ","userId":"06690068059315868411"},"user_tz":-540},"id":"1kiFqmAzs2rY","outputId":"73fce891-8d4f-4c86-bc43-14c95f716058"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33minsilicomab\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/Colab Notebooks/catalyst_metric_learning_defect/wandb/run-20230202_164914-pi787ten\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlambent-rabbit-3\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/insilicomab/catalyst-metric-learning-defective\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/insilicomab/catalyst-metric-learning-defective/runs/pi787ten\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n","/usr/local/lib/python3.8/dist-packages/catalyst/core/misc.py:119: UserWarning: No ``ICriterionCallback/CriterionCallback`` were found while runner.criterion is not None.Do you compute the loss during ``runner.handle_batch``?\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/catalyst/core/misc.py:127: UserWarning: No ``IBackwardCallback/BackwardCallback`` were found while runner.criterion/optimizer is not None.Do you backward the loss during ``runner.handle_batch``?\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/catalyst/core/misc.py:133: UserWarning: No ``IOptimizerCallback/OptimizerCallback`` were found while runner.optimizer is not None.Do run optimisation step pass during ``runner.handle_batch``?\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/catalyst/core/misc.py:139: UserWarning: No ``ISchedulerCallback/SchedulerCallback`` were found while runner.scheduler is not None.Do you make scheduler step during ``runner.handle_batch``?\n","  warnings.warn(\n","1/2 * Epoch (train): 100% 50/50 [00:20<00:00,  2.43it/s, accuracy=0.750, f1_score=0.733, fbeta_score=0.732, loss=3.523, precision=0.750, recall=0.833]\n","train (1/2) accuracy: 0.2700000000000001 | f1_score: 0.19485719835018803 | fbeta_score: 0.18704094974170635 | loss: 16.642981789894403 | precision: 0.32583337303581034 | recall: 0.2708333766120891\n","1/2 * Epoch (valid): 100% 13/13 [00:00<00:00, 14.85it/s, accuracy=0.000e+00, f1_score=1.000e-07, fbeta_score=1.562e-07, loss=27.576, precision=0.500, recall=0.500]\n","valid (1/2) accuracy: 0.4 | f1_score: 0.30095243777142344 | fbeta_score: 0.27697121439666544 | loss: 12.989259783625604 | precision: 0.6566666722297669 | recall: 0.5366666769981384\n","* Epoch (1/2) \n","2/2 * Epoch (train): 100% 50/50 [00:19<00:00,  2.53it/s, accuracy=0.750, f1_score=0.733, fbeta_score=0.732, loss=8.205, precision=0.750, recall=0.833]\n","train (2/2) accuracy: 0.7299999999999998 | f1_score: 0.6656190794706344 | fbeta_score: 0.6600080069899559 | loss: 4.016909969082536 | precision: 0.8083333459496497 | recall: 0.7408333459496497\n","2/2 * Epoch (valid): 100% 13/13 [00:00<00:00, 15.68it/s, accuracy=1.000, f1_score=1.000, fbeta_score=1.000, loss=1.328e-04, precision=1.000, recall=1.000]\n","valid (2/2) accuracy: 0.8400000000000002 | f1_score: 0.7969524025917054 | fbeta_score: 0.8138658761978149 | loss: 1.9087085923951965 | precision: 0.8400000095367433 | recall: 0.8966666746139527\n","* Epoch (2/2) \n","Top models:\n","model/pth/model.0002.pth\t1.9087\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:    accuracy_epoch/train ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:    accuracy_epoch/valid ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:    f1_score_epoch/train ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:    f1_score_epoch/valid ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m: fbeta_score_epoch/train ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m: fbeta_score_epoch/valid ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:        loss_epoch/train ‚ñà‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:        loss_epoch/valid ‚ñà‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m:   precision_epoch/train ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:   precision_epoch/valid ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:      recall_epoch/train ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m:      recall_epoch/valid ‚ñÅ‚ñà\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:    accuracy_epoch/train 0.73\n","\u001b[34m\u001b[1mwandb\u001b[0m:    accuracy_epoch/valid 0.84\n","\u001b[34m\u001b[1mwandb\u001b[0m:    f1_score_epoch/train 0.66562\n","\u001b[34m\u001b[1mwandb\u001b[0m:    f1_score_epoch/valid 0.79695\n","\u001b[34m\u001b[1mwandb\u001b[0m: fbeta_score_epoch/train 0.66001\n","\u001b[34m\u001b[1mwandb\u001b[0m: fbeta_score_epoch/valid 0.81387\n","\u001b[34m\u001b[1mwandb\u001b[0m:        loss_epoch/train 4.01691\n","\u001b[34m\u001b[1mwandb\u001b[0m:        loss_epoch/valid 1.90871\n","\u001b[34m\u001b[1mwandb\u001b[0m:   precision_epoch/train 0.80833\n","\u001b[34m\u001b[1mwandb\u001b[0m:   precision_epoch/valid 0.84\n","\u001b[34m\u001b[1mwandb\u001b[0m:      recall_epoch/train 0.74083\n","\u001b[34m\u001b[1mwandb\u001b[0m:      recall_epoch/valid 0.89667\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mlambent-rabbit-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/insilicomab/catalyst-metric-learning-defective/runs/pi787ten\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230202_164914-pi787ten/logs\u001b[0m\n","Error executing job with overrides: []\n","Traceback (most recent call last):\n","  File \"train.py\", line 78, in main\n","    wandb.save(hydra.utils.get_original_cwd() + 'model/pth/model.best.pth')\n","  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n","    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n","wandb.errors.Error: You must call wandb.init() before wandb.save()\n","\n","Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"]}],"source":["!python train.py"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.3 (main, Mar 21 2022, 20:30:42) [Clang 13.1.6 (clang-1316.0.21.2)]"},"vscode":{"interpreter":{"hash":"199558dbdb0489c9ed924a71da77983f21ef299bac2d31ff6534c27fc1b6fe26"}}},"nbformat":4,"nbformat_minor":0}